### Documentation & Knowledge Base Structure (2025-07-18)

1. The project documentation is split as follows:
   - `README.md`: Standard project README (summary, install, usage, links)
   - `requirements.md`: Project description, goals, roadmap, requirements, acceptance criteria
   - `design.md`: Technology stack, architecture, design guidelines, rationale
   - `todo_check_list.md`: All stages, phases, and subphases as a canonical checklist (progress tracking is done here)
   - `knowledgebase/`: Folder containing all technical knowledge, code examples, and implementation patterns, split into context-specific files (e.g., postgrest.md, rls.md, production_ownership.md, testing.md, etc.)

2. All contributors must:
   - Keep requirements, design, and checklist files up to date as features are added or changed
   - Add new knowledgebase files as needed and keep them organized by topic
   - Update navigation links in all docs as structure evolves

3. The workflow for research, planning, and implementation must reference and update these files at each phase and subphase:
   - Research and planning: Reference requirements.md, design.md, and knowledgebase/ for patterns and best practices.
   - Implementation: Write tests first, then implement features, updating todo_check_list.md and knowledgebase/ as needed.
   - After implementation: Document any new patterns, troubleshooting, or best practices in knowledgebase/.

4. The knowledgebase/ folder is the canonical source for all technical patterns, troubleshooting, and best practices. Before implementing any functionality, always check knowledgebase/ for relevant patterns, examples, or best practices. If new knowledge is gathered during implementation, add it to the appropriate file in knowledgebase/.

5. All previous documentation rules remain in effect unless superseded by this structure.

### Development Workflow & Rules

This is a strict, mandatory workflow. Each step must be followed precisely. Do not proceed to the next step without explicit user approval at the verification gates.

#### Phase 1: Mandatory Research & Planning

**This phase must be completed in full before any code is written or analyzed.**

1.  **Define Requirements (The "What"):**
    *   Clarify the precise business requirements for the feature.
    *   Break down the feature into a step-by-step implementation roadmap.
    *   **Action:** Update the `requirements.md` file with this plan.

2.  **Build Knowledge Base (The "How"):**
    *   **Prerequisite:** This is a mandatory, deep-dive research step.
    *   **Action:** Use the available Cursor tools to conduct thorough research:
        *   `codebase_search` - for semantic search within the project
        *   `grep_search` - for exact text/pattern matching
        *   `file_search` - for finding specific files
        *   `read_file` - for examining file contents
    *   **Source Priority:** Your research must prioritize sources in this order:
        1.  **Official Documentation** (e.g., postgrest.org, postgresql.org, hub.docker.com)
        2.  **Official or acknowledged GitHub Repositories** containing examples.
        3.  **Existing project files** for patterns and examples.
    *   **Content Requirement:** The research must produce **concrete code examples** that are directly applicable to the task.
    *   **Action:** Synthesize this research and the examples into the appropriate file(s) in the `knowledgebase/` folder.
    *   **Stuck?** If, after a thorough search, you cannot find sufficient information or clear examples, **STOP** and ask the user for help.

3.  **USER VERIFICATION GATE:**
    *   **STOP.**
    *   **Action:** Announce that Phase 1 is complete and present the gathered knowledge base content for review (pointing to the relevant file(s) in `knowledgebase/`).
    *   **Action:** Ask for explicit approval to proceed (e.g., "Is this knowledge base sufficient? May I proceed to the next step?").
    *   **DO NOT** move to Phase 2 without a "yes" or equivalent confirmation from the user.

#### Phase 2: Implementation Cycle (Test-Driven)

This cycle should be followed for *one feature at a time*.

1.  **Write Tests First:** Before implementing the feature's logic, write the corresponding automated tests based on the test design from Phase 1.
2.  **Implement Feature Code:** Write the minimum amount of code necessary to make the newly created tests pass.
3.  **User Verification:** After the initial implementation, pause and ask for user verification of the approach and the code.
4.  **Run All Tests:** Execute the *entire* test suite to ensure the new code passes its own tests and has not introduced any regressions.
    *   **If all tests pass:** The feature is considered complete. Proceed to the next feature.
    *   **If tests fail:** Proceed to Phase 3.
5.  **USER VERIFICATION GATE:**
    *   **STOP.**
    *   **Action:** Announce that Phase 2 is complete and present the code changes and test results.
    *   **Action:** Ask for explicit approval to proceed.
    *   **DO NOT** move to the next phase without approval.

#### Subphase Completion Protocol

**After each subphase (e.g., 1.1, 1.2, 2.1, etc.):**
1.  **STOP and BREAK**
2.  **Action:** Provide a brief explanation of what was implemented in the subphase
3.  **Action:** Explain the rationale for why this approach is the best option
4.  **Action:** Allow user to read and ask questions
5.  **Action:** Wait for user approval before proceeding to the next subphase

#### Phase 3: Troubleshooting & Code Quality

1.  **Isolate Failures:** If multiple tests fail, focus on fixing them *one at a time*. Start with the test most directly related to the new code.
2.  **Iterate Carefully:** Make targeted changes to the code to fix the failing test.
3.  **Prevent Regressions:** After each change, run the entire test suite again. If the change causes previously passing tests to fail, **revert the change immediately**. Discuss the problem with the user to find a better solution.
4.  **Handle Persistent Failures:** If a test fails repeatedly (e.g., 2-3 attempts) without a clear path to resolution, **stop**. Do not attempt random changes. Explain the issue to the user and ask for guidance.
5.  **Maintain Code Quality:** Avoid making superficial or nonsensical changes, such as arbitrarily renaming variables. All code changes must have a clear purpose.

#### Additional Efficiency Rules

1.  **Tool Usage Guidelines:**
    *   Use `codebase_search` for understanding existing code patterns and finding relevant examples.
    *   Use `grep_search` for finding specific function names, table names, or exact text matches.
    *   Use `read_file` to examine specific files or sections when you need detailed context.
    *   Use `file_search` when you know part of a filename but not its exact location.

2.  **Knowledge Base Management:**
    *   Always update the appropriate file(s) in `knowledgebase/` with new research findings and code examples.
    *   Keep the knowledge base organized by technology/topic.
    *   Include both working examples and common error patterns.

3.  **Testing Strategy:**
    *   Write tests that cover both success and failure scenarios.
    *   Include edge cases and boundary conditions.
    *   Test both API endpoints and direct database functions.

4.  **Documentation:**
    *   Update `requirements.md`, `design.md`, and `todo_check_list.md` with implementation progress and changes.
    *   Keep `knowledgebase/` current with all technical details.
    *   Document any deviations from the original plan.
    *   **Progress Tracking:** Mark completed tasks as resolved in `todo_check_list.md` when user confirms successful completion.

5. Before implementing any functionality, always check the knowledgebase/ folder for relevant patterns, examples, or best practices. If new knowledge is gathered during implementation, add it to the appropriate file in knowledgebase/.